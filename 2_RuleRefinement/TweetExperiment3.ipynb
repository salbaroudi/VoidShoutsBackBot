{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12ktweets.twts', 'rule1-4_trial3.twts', 'ProposedRules.txt', 'testtweets.twts', 'testdatasets', 'self.twts', 'rule1-4_pubmetrics2.twts', '6ktweets.twts', '40ktweets.twts', 'rule1-4_pubmetrics.twts', 'selectedtweets', 'rules3-4_trial2.twts', 'rules1-4_trial1.twts', 'skeptic.twts']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./data\"))\n",
    "\n",
    "testFilePath = \"./data/rule1-4_pubmetrics.twts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, some hypotheses checks will be done on our newly filtered data. First, I will adjust our stream parameters. It will be changed to:\n",
    "\n",
    "```\n",
    "https://api.twitter.com/2/tweets/search/stream?tweet.fields=created_at,public_metrics&expansions=author_id,referenced_tweets.id\n",
    "```\n",
    "where *referenced_tweets.id* has been added to our parameter listing.\n",
    "\n",
    "Next, for our two most popular rules (SocietalShift, and SelfAndID), additional negative constraints will be added: *\" -is:retweet -is:quote -is:reply\"*\n",
    "\n",
    "Which will cut down our search to only original posts. The two less popular rules will not recieve these constraints, as there match rate is very low.\n",
    "\n",
    "Analysis will be done on the tweets and metrics recorded on the two sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test1: SocietalShift and SelfAndID tagged tweets are original tweets.\n",
    "\n",
    "This means that we should not see \"RT\" appended to the tweet text. \"@\" symbols may be still be used mention others in original tweets.\n",
    "\n",
    "I visually inspected a few raw tweets, for the tag \"SocietalShift\". Already, I can see that there are quotes and retweets present...eventhough I never requested this.\n",
    "\n",
    "Question: For an Original Tweet (not Q, RT or Rep), (i) will the referenced tweet field show up? (ii) Will the public metrics near the top of the jsonObj be filled in?\n",
    "\n",
    "Answer: Using the following two curl requests:\n",
    "\n",
    "```\n",
    "curl --request GET 'https://api.twitter.com/2/tweets?ids=1565347524013338625&tweet.fields=author_id,id,public_metrics,referenced_tweets,text&expansions=referenced_tweets.id' --header 'Authorization: Bearer <?>'\n",
    "\n",
    "curl --request GET 'https://api.twitter.com/2/tweets?ids=1565587106101174274&tweet.fields=author_id,id,public_metrics,referenced_tweets,text&expansions=referenced_tweets.id' --header 'Authorization: Bearer <?>'\n",
    "\n",
    "```\n",
    "\n",
    "(i) No. As there are no referenced tweets, so the extension is not included in the json Payload.\n",
    "\n",
    "(i) YES! And this means if we do see this top level subobject with non-zero values, that it must be an original tweet.\n",
    "\n",
    "Non zero L, R, Q on top level public_metrics => original tweet.\n",
    "Zero values /=> original tweet (it may or may not be - usually it is not).\n",
    "\n",
    "**More simply, we can detect if a tweet is original if the referenced tweet field is present, or not.**\n",
    "\n",
    "So to begin, lets extend our dataframe fields, and gather some more data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26407 entries, 0 to 26406\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tweetid        26407 non-null  int64 \n",
      " 1   text           26407 non-null  object\n",
      " 2   created_at     26407 non-null  object\n",
      " 3   tagid          26407 non-null  int64 \n",
      " 4   tag            26407 non-null  object\n",
      " 5   userid         26407 non-null  int64 \n",
      " 6   username       26407 non-null  object\n",
      " 7   rtcount        26407 non-null  int16 \n",
      " 8   repcount       26407 non-null  int16 \n",
      " 9   likecount      26407 non-null  int16 \n",
      " 10  qtcount        26407 non-null  int16 \n",
      " 11  tweet_type     26407 non-null  object\n",
      " 12  ref_tweetid    26407 non-null  int64 \n",
      " 13  ref_authorid   26407 non-null  int64 \n",
      " 14  ref_rtcount    26407 non-null  int16 \n",
      " 15  ref_repcount   26407 non-null  int16 \n",
      " 16  ref_likecount  26407 non-null  int16 \n",
      " 17  ref_qtcount    26407 non-null  int16 \n",
      "dtypes: int16(8), int64(5), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Main import and cleaning code goes here.\n",
    "\n",
    "#String, Int -> DataFrame!\n",
    "def generatedataframe(path,writeLimit):\n",
    "    if ((type(writeLimit) != int)):\n",
    "        raise(\"Error: writeLimit not an integer. Check argument.\")\n",
    "        \n",
    "    cols = [\"tweetid\", \"text\", \"created_at\",\n",
    "            \"tagid\",\"tag\",\"userid\",\"username\",\n",
    "            \"rtcount\",\"repcount\",\"likecount\",\n",
    "            \"qtcount\",\"tweet_type\",\"ref_tweetid\", \"ref_authorid\",\n",
    "            \"ref_rtcount\",\"ref_repcount\",\"ref_likecount\",\n",
    "            \"ref_qtcount\"]\n",
    "    tempDF = pd.DataFrame(columns=cols)\n",
    "    tweetDF = pd.DataFrame(columns=cols)\n",
    "    lineCount = 0\n",
    "    ##Note! On a rare occasion, two or more tags can match. THis currently chooses the first tag set\n",
    "    ##Information loss can occur.\n",
    "    with open(path) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            if (lineCount == writeLimit):\n",
    "                tweetDF = pd.concat([tweetDF,tempDF],copy=False).reset_index().drop(columns=\"index\")\n",
    "                tempDF = pd.DataFrame(columns=cols) #blow it all to hell!!\n",
    "                lineCount = 0\n",
    "            jsonObj = json.loads(line)\n",
    "            #done for readibility, not code terseness\n",
    "            c1 = jsonObj[\"data\"][\"id\"]\n",
    "            c2 = jsonObj[\"data\"][\"text\"]\n",
    "            c3 = jsonObj[\"data\"][\"created_at\"]\n",
    "            c4 = jsonObj['matching_rules'][0][\"id\"]\n",
    "            c5 = jsonObj['matching_rules'][0][\"tag\"]\n",
    "            c6 = jsonObj[\"data\"][\"author_id\"]\n",
    "            #Note: This assumes the first includes user is the poster (!)\n",
    "            c7 = jsonObj[\"includes\"][\"users\"][0][\"username\"]\n",
    "            c8 = jsonObj[\"data\"][\"public_metrics\"][\"retweet_count\"]\n",
    "            c9 = jsonObj[\"data\"][\"public_metrics\"][\"reply_count\"]\n",
    "            c10 = jsonObj[\"data\"][\"public_metrics\"][\"like_count\"]\n",
    "            c11 = jsonObj[\"data\"][\"public_metrics\"][\"quote_count\"]\n",
    "            \n",
    "            #Now check to see if our tweet is Original or Not.\n",
    "            c12 = \"original\"\n",
    "            c13 = 0\n",
    "            if (\"referenced_tweets\" in jsonObj[\"data\"]):\n",
    "                c12 = jsonObj[\"data\"][\"referenced_tweets\"][0][\"type\"]\n",
    "                c13 = jsonObj[\"data\"][\"referenced_tweets\"][0][\"id\"]\n",
    "            \n",
    "            #If there is a referenced tweet, get its metrics\n",
    "            c14 = 0 #\"ref_authorid\"\n",
    "            c15 = 0 #\"ref_trcount\" \n",
    "            c16 = 0 #\"ref_repcount\" \n",
    "            c17 = 0 #\"ref_likecount\"\n",
    "            c18 = 0 #\"ref_qtcount\"\n",
    "            if (\"tweets\" in jsonObj[\"includes\"]):\n",
    "                c14 = jsonObj[\"includes\"][\"tweets\"][0][\"author_id\"] #\"ref_authorid\"\n",
    "                c15 = jsonObj[\"includes\"][\"tweets\"][0][\"public_metrics\"][\"retweet_count\"] #\"ref_trcount\" \n",
    "                c16 = jsonObj[\"includes\"][\"tweets\"][0][\"public_metrics\"][\"reply_count\"] #\"ref_repcount\" \n",
    "                c17 = jsonObj[\"includes\"][\"tweets\"][0][\"public_metrics\"][\"like_count\"] #\"ref_likecount\"\n",
    "                c18 = jsonObj[\"includes\"][\"tweets\"][0][\"public_metrics\"][\"quote_count\"] #\"ref_qtcount\"\n",
    "\n",
    "            tempDF.loc[len(tempDF.index)] = [c1,c2,c3,c4,c5,c6,c7,c8,c9,c10,c11,c12,c13,c14,c15,c16,c17,c18]    \n",
    "    \n",
    "            line = fp.readline()\n",
    "            lineCount = lineCount + 1\n",
    "                \n",
    "        if (lineCount > 0): #cadd the last of the rows to final tweetDF.\n",
    "            tweetDF = pd.concat([tweetDF,tempDF],copy=False).reset_index().drop(columns=\"index\")\n",
    "        fp.close()\n",
    "        \n",
    "    #Quickly convert to numbers.\n",
    "    #Unlikely we will hit over 2^16 for tweet metrics. Also, are targets are little people anyways,\n",
    "    #not huge twitter accounts. Downcasting will save some space.\n",
    "    tweetDF = tweetDF.astype({\"tweetid\": \"int64\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"tagid\": \"int64\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"userid\": \"int64\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"rtcount\": \"int16\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"repcount\": \"int16\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"likecount\": \"int16\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"qtcount\": \"int16\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"ref_tweetid\": \"int64\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"ref_authorid\": \"int64\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"ref_rtcount\": \"int16\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"ref_repcount\": \"int16\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"ref_likecount\": \"int16\"}, copy=False) \n",
    "    tweetDF = tweetDF.astype({\"ref_qtcount\": \"int16\"}, copy=False) \n",
    "\n",
    "    #[!] for now, I don't use the date string, eventhough it is recorded. To be formatted into a DateTime object later\n",
    "\n",
    "    tweetDF.info()\n",
    "    return tweetDF\n",
    "\n",
    "tweetDF = generatedataframe(testFilePath,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tagid</th>\n",
       "      <th>tag</th>\n",
       "      <th>userid</th>\n",
       "      <th>username</th>\n",
       "      <th>rtcount</th>\n",
       "      <th>repcount</th>\n",
       "      <th>likecount</th>\n",
       "      <th>qtcount</th>\n",
       "      <th>tweet_type</th>\n",
       "      <th>ref_tweetid</th>\n",
       "      <th>ref_authorid</th>\n",
       "      <th>ref_rtcount</th>\n",
       "      <th>ref_repcount</th>\n",
       "      <th>ref_likecount</th>\n",
       "      <th>ref_qtcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26402</th>\n",
       "      <td>1564733345241698304</td>\n",
       "      <td>Duvido mt q essa parada do Mineirão aconteça, ...</td>\n",
       "      <td>2022-08-30T21:54:35.000Z</td>\n",
       "      <td>1563582770315665411</td>\n",
       "      <td>HealthySkepticism</td>\n",
       "      <td>964120169034510336</td>\n",
       "      <td>AlexAgiotagens</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26403</th>\n",
       "      <td>1564733346260946946</td>\n",
       "      <td>RT @cooltxchick: J.D. Vance is a bird of a fea...</td>\n",
       "      <td>2022-08-30T21:54:35.000Z</td>\n",
       "      <td>1564718289544151040</td>\n",
       "      <td>SelfandID</td>\n",
       "      <td>948410690464759809</td>\n",
       "      <td>JonZimmerman16</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>retweeted</td>\n",
       "      <td>1564428649603940355</td>\n",
       "      <td>22803269</td>\n",
       "      <td>308</td>\n",
       "      <td>23</td>\n",
       "      <td>643</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26404</th>\n",
       "      <td>1564733347531816965</td>\n",
       "      <td>And a very proud Vmate. You forgot to add that...</td>\n",
       "      <td>2022-08-30T21:54:36.000Z</td>\n",
       "      <td>1564718289544151040</td>\n",
       "      <td>SelfandID</td>\n",
       "      <td>1508910788026765314</td>\n",
       "      <td>LeloGotStacks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>quoted</td>\n",
       "      <td>1564726297665933315</td>\n",
       "      <td>228109780</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26405</th>\n",
       "      <td>1564733345426292736</td>\n",
       "      <td>ser fã de artista internacional e pobre ao msm...</td>\n",
       "      <td>2022-08-30T21:54:35.000Z</td>\n",
       "      <td>1563582770315665411</td>\n",
       "      <td>HealthySkepticism</td>\n",
       "      <td>1222967589732802560</td>\n",
       "      <td>unfuckbrave</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26406</th>\n",
       "      <td>1564733348727214081</td>\n",
       "      <td>@urlovelybones as legendas no msm nivel daquel...</td>\n",
       "      <td>2022-08-30T21:54:36.000Z</td>\n",
       "      <td>1563582770315665411</td>\n",
       "      <td>HealthySkepticism</td>\n",
       "      <td>1488538249492639747</td>\n",
       "      <td>cumskinnyy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>1564733044396900355</td>\n",
       "      <td>1517981648935165954</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweetid                                               text  \\\n",
       "26402  1564733345241698304  Duvido mt q essa parada do Mineirão aconteça, ...   \n",
       "26403  1564733346260946946  RT @cooltxchick: J.D. Vance is a bird of a fea...   \n",
       "26404  1564733347531816965  And a very proud Vmate. You forgot to add that...   \n",
       "26405  1564733345426292736  ser fã de artista internacional e pobre ao msm...   \n",
       "26406  1564733348727214081  @urlovelybones as legendas no msm nivel daquel...   \n",
       "\n",
       "                     created_at                tagid                tag  \\\n",
       "26402  2022-08-30T21:54:35.000Z  1563582770315665411  HealthySkepticism   \n",
       "26403  2022-08-30T21:54:35.000Z  1564718289544151040          SelfandID   \n",
       "26404  2022-08-30T21:54:36.000Z  1564718289544151040          SelfandID   \n",
       "26405  2022-08-30T21:54:35.000Z  1563582770315665411  HealthySkepticism   \n",
       "26406  2022-08-30T21:54:36.000Z  1563582770315665411  HealthySkepticism   \n",
       "\n",
       "                    userid        username  rtcount  repcount  likecount  \\\n",
       "26402   964120169034510336  AlexAgiotagens        0         0          0   \n",
       "26403   948410690464759809  JonZimmerman16      308         0          0   \n",
       "26404  1508910788026765314   LeloGotStacks        0         0          0   \n",
       "26405  1222967589732802560     unfuckbrave        0         0          0   \n",
       "26406  1488538249492639747      cumskinnyy        0         0          0   \n",
       "\n",
       "       qtcount  tweet_type          ref_tweetid         ref_authorid  \\\n",
       "26402        0    original                    0                    0   \n",
       "26403        0   retweeted  1564428649603940355             22803269   \n",
       "26404        0      quoted  1564726297665933315            228109780   \n",
       "26405        0    original                    0                    0   \n",
       "26406        0  replied_to  1564733044396900355  1517981648935165954   \n",
       "\n",
       "       ref_rtcount  ref_repcount  ref_likecount  ref_qtcount  \n",
       "26402            0             0              0            0  \n",
       "26403          308            23            643           10  \n",
       "26404           15             5             42            2  \n",
       "26405            0             0              0            0  \n",
       "26406            0             1              0            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetDF.tail(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check: Distribution of Tweet Types, and Tags:\n",
    "\n",
    "(I) Our percentages for our tags have not shifted too much from last time, even with added constraints for two of the tags.\n",
    "\n",
    "(II) The tweet type percentage chart is interesting. Only 11% of tweets are original, everything else is reactive content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62251/3737709089.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  distDF[\"percentage\"][strIndex] = (distDF[\"sum\"][strIndex]*100)/totalSum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SelfandID</th>\n",
       "      <td>16530</td>\n",
       "      <td>62.597039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HealthySkepticism</th>\n",
       "      <td>8077</td>\n",
       "      <td>30.586587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocietalShift</th>\n",
       "      <td>1778</td>\n",
       "      <td>6.733063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SearchTheVoid</th>\n",
       "      <td>22</td>\n",
       "      <td>0.083311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sum percentage\n",
       "SelfandID          16530  62.597039\n",
       "HealthySkepticism   8077  30.586587\n",
       "SocietalShift       1778   6.733063\n",
       "SearchTheVoid         22   0.083311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62251/3737709089.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  typeDF[\"percentage\"][strIndex] = (typeDF[\"sum\"][strIndex]*100)/totalSum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>replied_to</th>\n",
       "      <td>10079</td>\n",
       "      <td>38.16791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retweeted</th>\n",
       "      <td>11820</td>\n",
       "      <td>44.760859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>2869</td>\n",
       "      <td>10.864543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoted</th>\n",
       "      <td>1639</td>\n",
       "      <td>6.206688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sum percentage\n",
       "replied_to  10079   38.16791\n",
       "retweeted   11820  44.760859\n",
       "original     2869  10.864543\n",
       "quoted       1639   6.206688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get a tag percentage summary\n",
    "distDF = pd.DataFrame(columns=[\"sum\",\"percentage\"],index=tweetDF.tag.unique())\n",
    "distDF[\"sum\"] = tweetDF.groupby('tag')['tagid'].count()\n",
    "totalSum = tweetDF.shape[0]\n",
    "for strIndex in distDF.index:\n",
    "    distDF[\"percentage\"][strIndex] = (distDF[\"sum\"][strIndex]*100)/totalSum\n",
    "\n",
    "display(distDF)\n",
    "\n",
    "#Get a tweet type Percentage Summary\n",
    "typeDF = pd.DataFrame(columns=[\"sum\",\"percentage\"],index=tweetDF.tweet_type.unique())\n",
    "typeDF[\"sum\"] = tweetDF.groupby('tweet_type')['ref_tweetid'].count()\n",
    "totalSum = tweetDF.shape[0]\n",
    "for strIndex in typeDF.index:\n",
    "    typeDF[\"percentage\"][strIndex] = (typeDF[\"sum\"][strIndex]*100)/totalSum\n",
    "\n",
    "display(typeDF)\n",
    "\n",
    "#finally., lets get our original v.s everything else ratio:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: Can sum(Reply Metrics) > sum(Ref Tweet Metrics). How often does this occur? \n",
    "\n",
    "640 times, or 2.5% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurs: 640 times\n",
      "Occurs: 2.423599803082516 percent of the time\n"
     ]
    }
   ],
   "source": [
    "tDF = tweetDF #shortens...\n",
    "querySum = (((tDF[\"rtcount\"] + tDF[\"repcount\"] + tDF[\"qtcount\"] + tDF[\"likecount\"])) > ((tDF[\"ref_rtcount\"] + tDF[\"ref_repcount\"] + tDF[\"ref_qtcount\"] + tDF[\"ref_likecount\"]))).sum()\n",
    "print(\"Occurs:\",querySum,\"times\")\n",
    "print(\"Occurs:\",(100*querySum/tweetDF.shape[0]),\"percent of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check: How many non-original tweets do our modified tags?\n",
    "\n",
    "I specified that no replies, quotes or retweets be selected for the \n",
    "\"HealthySkepticism\" and \"SelfAndID\" tagged tweets. It appears that many of these tweets got through the filter. But just how many?\n",
    "\n",
    "Answer: There are a lot of tweets that get past the filter. 13 and 6.5% of them are filtered erroneously. Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Non Original Tweets for HS: 13.272254549956667\n",
      "Percentage of Non Original Tweets for Sai: 6.485178463399879\n"
     ]
    }
   ],
   "source": [
    "hsTagSum = (tweetDF[\"tag\"] == \"HealthySkepticism\").sum()\n",
    "saiTagSum = (tweetDF[\"tag\"] == \"SelfandID\").sum()\n",
    "\n",
    "#Select all tweets that have HealthySkepticism tags, and count the originals.\n",
    "#it will likely still be 10%\n",
    "hsSubSet = tweetDF[tweetDF[\"tag\"] == \"HealthySkepticism\"]\n",
    "hsOrigTotal = hsSubSet[ hsSubSet[\"tweet_type\"] == \"original\" ].shape[0]\n",
    "print(\"Percentage of Non Original Tweets for HS:\", (100*hsOrigTotal/hsTagSum))\n",
    "\n",
    "saiSubSet = tweetDF[tweetDF[\"tag\"] == \"SelfandID\"]\n",
    "saiOrigTotal = hsSubSet[ hsSubSet[\"tweet_type\"] == \"original\" ].shape[0]\n",
    "print(\"Percentage of Non Original Tweets for Sai:\", (100*saiOrigTotal/saiTagSum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of RTs::45.03730071571932\n",
      "Percentage of ATs::83.01586700496081\n"
     ]
    }
   ],
   "source": [
    "#remember that we can plug in a series of truth values, to pick out rows.\n",
    "rtCount = tweetDF[tweetDF[\"text\"].str.contains(\"RT\")].shape[0]\n",
    "atCount = tweetDF[tweetDF[\"text\"].str.contains(\"@\")].shape[0]\n",
    "\n",
    "print(\"Percentage of RTs::\" + str(100*rtCount/tweetDF.shape[0]))\n",
    "print(\"Percentage of ATs::\" + str(100*atCount/tweetDF.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining User Names to our tweetDF Dataframe\n",
    "\n",
    "When fetching tweets, we can get a userID, but not user information directly.\n",
    "\n",
    "From our stream URL Parameters, we can screen out users based on\n",
    "there follows, likes, etc. It would be a good idea to verify that our limits.\n",
    "\n",
    "were enforced. As seen previously, I asked for no replies/qt/retweets,\n",
    "and only 10% of the tweets ended up original.\n",
    "\n",
    "For this next section, usernames are exported from the tweetDF dataframe, and a node.js script is used to fetch all the user information.\n",
    "\n",
    "Looking at our code (that uses Bearer Token Authentication), it works as a Get Request. This means we cannot load too many users, as they will be URL encoded (max length for URL). Googling around, we can't send more than 2kilobytes...our user list is 250kb+. So that doesnt work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An example of our user names\n",
    "tweetDF[\"username\"].iloc[20:40]\n",
    "#Lets write our usernames to file:\n",
    "\n",
    "#tweetDF.loc[:, ['username']].to_csv(\"./data/users.csv\", sep='\\t', encoding='utf-8',index=False)\n",
    "pd.Series(tweetDF.username.unique()).to_csv(\"./data/users.csv\", sep='\\t', encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "cite2c": {
   "citations": {
    "8394687/9ZZ65S4Q": {
     "author": [
      {
       "family": "M. Cvetkovic",
       "given": "Dragos"
      },
      {
       "family": "Doob",
       "given": "Michael"
      },
      {
       "family": "Sachs",
       "given": "Horst"
      }
     ],
     "collection-title": "Pure and Applied Mathematics",
     "edition": "1st",
     "id": "8394687/9ZZ65S4Q",
     "issued": {
      "year": 1980
     },
     "language": "English",
     "number-of-pages": "368",
     "number-of-volumes": "1",
     "publisher": "Academic Press",
     "shortTitle": "Spectra of Graphs",
     "title": "Spectra of Graphs: Theory and Application",
     "title-short": "Spectra of Graphs",
     "type": "book",
     "volume": "87"
    },
    "8394687/EVEKS8I8": {
     "URL": "https://forum.bodybuilding.com/showthread.php?t=166912491&subId3=xid:fr1605396294772jac",
     "container-title": "Cocoa as weight-loss accelerator: Study",
     "genre": "Post",
     "id": "8394687/EVEKS8I8",
     "issued": {
      "day": 26,
      "month": 3,
      "year": 2015
     },
     "language": "English",
     "title": "Cocoa as weight-loss accelerator: Study",
     "type": "post"
    },
    "8394687/FB5G7ZR9": {
     "URL": "https://informationisbeautiful.net/visualizations/snake-oil-scientific-evidence-for-nutritional-supplements-vizsweet/",
     "author": [
      {
       "family": "David McCandless",
       "given": ""
      },
      {
       "family": "Dr Stephanie Starling",
       "given": ""
      },
      {
       "family": "et. al",
       "given": ""
      }
     ],
     "container-title": "Snake-Oil Supplements",
     "genre": "Infographic",
     "id": "8394687/FB5G7ZR9",
     "issued": {
      "day": 24,
      "month": 4,
      "year": 2019
     },
     "language": "English",
     "shortTitle": "Snake-Oil Supp.",
     "title": "Snake-Oil Supplements",
     "title-short": "Snake-Oil Supp.",
     "type": "webpage"
    },
    "8394687/SZS6I8KD": {
     "URL": "https://www.imdb.com/title/tt0119177/?ref_=fn_al_tt_1",
     "author": [
      {
       "family": "Niccol",
       "given": "Andrew"
      }
     ],
     "genre": "Sci-Fi, Drama",
     "id": "8394687/SZS6I8KD",
     "issued": {
      "day": 24,
      "month": 10,
      "year": 1997
     },
     "language": "English",
     "publisher": "Colombia Pictures",
     "shortTitle": "Gattaca",
     "title": "Gattaca",
     "title-short": "Gattaca",
     "type": "motion_picture"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
